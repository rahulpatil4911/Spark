ordersCSV = spark.read.csv('/public/retail_db/orders'). \
  toDF('order_id', 'order_date', 'order_customer_id', 'order_status')

from pyspark.sql.types import IntegerType, FloatType
orders = ordersCSV. \
  withColumn('order_id', ordersCSV.order_id.cast(IntegerType())). \
  withColumn('order_customer_id', ordersCSV.order_customer_id.cast(IntegerType()))

orders.selectExpr("concat(order_id, '\00', order_date, '\00', order_customer_id, '\00', order_status)"). \
  write. \
  text('/user/training/bootcampdemo/pyspark/orders_null')

orders.write.csv('/user/training/bootcampdemo/pyspark/orders_null', '\00')

orders_read_csv = spark.read.csv('/user/training/bootcampdemo/pyspark/orders_null', sep='\00'). \
  toDF('order_id', 'order_date', 'order_customer_id', 'order_status')

orders_read = orders_read_csv. \
  withColumn('order_id', orders_read_csv.order_id.cast(IntegerType())). \
  withColumn('order_customer_id', orders_read_csv.order_customer_id.cast(IntegerType()))

orders_read.show()
orders_read.printSchema()