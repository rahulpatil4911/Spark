# Get count by status from orders

spark.sql('select order_status, count(1) status_count '
          'from orders group by order_status'). \
  show()

# Get revenue for each order id from order items 

spark.sql('select order_item_order_id, sum(order_item_subtotal) order_revenue '
          'from order_items group by order_item_order_id'). \
  show()

# Get daily product revenue 
# filter for complete and closed orders
# groupBy order_date and order_item_product_id
# Use agg and sum on order_item_subtotal to get revenue

spark.conf.set('spark.sql.shuffle.partitions', '2')

spark.sql('select o.order_date, oi.order_item_product_id, '
          'sum(oi.order_item_subtotal) order_revenue '
          'from orders o join order_items oi '
          'on o.order_id = oi.order_item_order_id '
          'where o.order_status in ("COMPLETE", "CLOSED") '
          'group by o.order_date, oi.order_item_product_id'). \
  show()